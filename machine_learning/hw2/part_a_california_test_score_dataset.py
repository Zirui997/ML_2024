# -*- coding: utf-8 -*-
"""Part A California Test Score dataset

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16qWQQ8FexPz8PzZwAJdk2piTDv1AlXAc
"""

#Step 1: Import the California Test Score Dataset

# Import necessary libraries
import pandas as pd

# Load the dataset from the provided URL
url = "https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Caschool.csv"
data = pd.read_csv(url)

# Display the first few rows of the dataset to understand its structure
data.head()

#Step 2: Visualize the Univariate Distribution of the Target Feature and Continuous Explanatory Variables

# Import necessary libraries for visualization
import matplotlib.pyplot as plt
import seaborn as sns

# Select target variable and three continuous explanatory variables
features = ['testscr', 'avginc', 'mealpct', 'calwpct']

# Plot univariate distributions for each feature
plt.figure(figsize=(10, 6))
for i, feature in enumerate(features):
    plt.subplot(2, 2, i+1)
    sns.histplot(data[feature], kde=True)
    plt.title(f'Distribution of {feature}')
plt.tight_layout()
plt.show()

#Step 3: Visualize the Dependency of the Target on Each Featur

# Plot scatter plots to show the dependency between target and selected features
plt.figure(figsize=(10, 6))
for i, feature in enumerate(features[1:]):  # Exclude 'testscr' itself
    plt.subplot(1, 3, i+1)
    sns.scatterplot(x=data[feature], y=data['testscr'])
    plt.title(f'{feature} vs testscr')
plt.tight_layout()
plt.show()

#Step 4: Splitting the Data into Training and Test Sets and Building Models

# Drop the non-numeric columns, including 'grspan'
X = data.drop(columns=['testscr', 'readscr', 'mathscr', 'distcod', 'county', 'district', 'grspan'])

# Check the data types to ensure only numeric columns are left
print(X.dtypes)

# Now split the data into training and test sets again
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the models again
knn = KNeighborsRegressor()
linear_reg = LinearRegression()
ridge = Ridge()
lasso = Lasso()

# Cross-validation evaluation for each model
models = {'KNN': knn, 'Linear Regression': linear_reg, 'Ridge': ridge, 'Lasso': lasso}

# Evaluate each model using cross-validation
for name, model in models.items():
    scores = cross_val_score(model, X_train, y_train, cv=5)
    print(f"{name}: Mean CV Score = {scores.mean():.4f}")

#Step 5: Running Models with and Without StandardScaler

from sklearn.preprocessing import StandardScaler

# Apply StandardScaler to the data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Evaluate models with scaled data
for name, model in models.items():
    scores_scaled = cross_val_score(model, X_train_scaled, y_train, cv=5)
    print(f"{name} with StandardScaler: Mean CV Score = {scores_scaled.mean():.4f}")

#Step 6: Tune Parameters Using GridSearchCV

from sklearn.model_selection import GridSearchCV

# Define parameter grids for tuning
param_grid_knn = {'n_neighbors': [3, 5, 7, 9]}
param_grid_ridge = {'alpha': [0.1, 1, 10, 100]}
param_grid_lasso = {'alpha': [0.1, 1, 10, 100]}

# Perform GridSearchCV for each model
grid_knn = GridSearchCV(KNeighborsRegressor(), param_grid_knn, cv=5)
grid_ridge = GridSearchCV(Ridge(), param_grid_ridge, cv=5)
grid_lasso = GridSearchCV(Lasso(), param_grid_lasso, cv=5)

# Fit the models using GridSearchCV
grid_knn.fit(X_train_scaled, y_train)
grid_ridge.fit(X_train_scaled, y_train)
grid_lasso.fit(X_train_scaled, y_train)

# Print the best parameters for each model
print(f"KNN: Best Parameters = {grid_knn.best_params_}")
print(f"Ridge: Best Parameters = {grid_ridge.best_params_}")
print(f"Lasso: Best Parameters = {grid_lasso.best_params_}")

#Step 7: Compare Coefficients of Two Best Linear Models (Ridge and Lasso)

# Fit Ridge and Lasso on the scaled training data
ridge_best = grid_ridge.best_estimator_
lasso_best = grid_lasso.best_estimator_

# Fit the models
ridge_best.fit(X_train_scaled, y_train)
lasso_best.fit(X_train_scaled, y_train)

# Compare coefficients
print("Ridge Regression Coefficients:", ridge_best.coef_)
print("Lasso Regression Coefficients:", lasso_best.coef_)

#Step 8: Discuss the Final Model Choice

# Get cross-validated scores for each model with the best parameters
knn_best = grid_knn.best_estimator_
ridge_best = grid_ridge.best_estimator_
lasso_best = grid_lasso.best_estimator_

# Perform cross-validation to get the final scores
knn_score = cross_val_score(knn_best, X_train_scaled, y_train, cv=5).mean()
ridge_score = cross_val_score(ridge_best, X_train_scaled, y_train, cv=5).mean()
lasso_score = cross_val_score(lasso_best, X_train_scaled, y_train, cv=5).mean()

# Output the scores for comparison
print(f"KNN Best Mean CV Score: {knn_score:.4f}")
print(f"Ridge Best Mean CV Score: {ridge_score:.4f}")
print(f"Lasso Best Mean CV Score: {lasso_score:.4f}")

# Find the best performing model based on the scores
if max(knn_score, ridge_score, lasso_score) == knn_score:
    best_model = 'KNN'
elif max(knn_score, ridge_score, lasso_score) == ridge_score:
    best_model = 'Ridge'
else:
    best_model = 'Lasso'

print(f"The best performing model is: {best_model}")